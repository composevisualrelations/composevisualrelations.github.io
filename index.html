<!DOCTYPE html>
<html lang="en">

<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-LP32F6JVKW"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());
        gtag('config', 'G-LP32F6JVKW');

       function setImageClevr(select){
           var image = document.getElementsByName("image-swap-1")[0];
           image.src = select.options[select.selectedIndex].value;
        }

        function setImageiGibson(select){
           var image = document.getElementsByName("image-swap-2")[0];
           image.src = select.options[select.selectedIndex].value;
        }
    </script>

    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css"
          integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">
    <!-- Custom styles for this template -->
    <link href="files/jumbotron.css" rel="stylesheet">

    <style type="text/css">
        a:hover {
            color: #000;
        }

        a::before {
            content: "";
            position: absolute;
            display: block;
            width: 100%;
            height: 1px;
            bottom: 0;
            left: 0;
            background-color: #000;
            transform: scaleX(0);
            transition: transform 0.3s ease;
        }
        select {
          /* for Firefox */
          /*-moz-appearance: none;*/
          /* for Chrome */
          /*-webkit-appearance: none;*/
        }
        .dropselect {
            background-repeat: repeat-x;
            background-size: 1px 1px;
            background-position: 0 85%;
            border: none;
            outline: none;
            scroll-behavior: smooth;
            border-bottom:solid 1px #000;
            width:auto;
            font-weight: bolder;
        }
        .dropselect option {
          color: initial; /* fix Windows bug */
        }

        .bibtexsection {
            font-family: "Courier",monospace;
            font-size: 16px;
            white-space: pre;
            background-color: #f4f4f4;
            text-align: left;
        }
    </style>
    <title>Learning to Compose Visual Relations</title>

</head>

<title>Learning to Compose Visual Relations</title>

<body>
<nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark">
    <a class="navbar-brand" href="#">Learning to Compose Visual Relations</a>

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarToggle">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarToggle">
        <ul class="navbar-nav ml-auto">
            <li class="nav-item">
                <a class="nav-link" href="#">Home</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="#Abstract">Abstract</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="#Paper">Paper</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="#Results">Results</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="#Model">Model</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="#Related">Related Work</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="#Contact">Contacts</a>
            </li>
        </ul>
    </div>
</nav>

<div class="container" style="padding-top: 80px; font-size: 20px">
    <div align="center">
        <h2 class="text-center" align="center">
            <p>Learning to Compose Visual Relations</p>
        </h2>
        <p style="color: #EB6D18"><b>NeurIPS 2021 (Spotlight)</b></p>
        <a href="https://nanliu.io/">Nan Liu</a><sup>1*</sup> &nbsp;
        <a href="https://shuangli59.github.io/">Shuang Li</a><sup>2*</sup> &nbsp;
        <a href="https://yilundu.github.io">Yilun Du</a><sup>2*</sup> &nbsp;
        <a href="https://mitibmwatsonailab.mit.edu/people/joshua-tenenbaum/">Joshua B. Tenenbaum</a><sup>2</sup> &nbsp;
        <a href="https://groups.csail.mit.edu/vision/torralbalab/">Antonio Torralba</a><sup>2</sup>
        <!-- <br> -->
        <a>(* indicate equal contribution)</a>
        <br>
        <!-- <small>(* indicate equal contribution)</small> -->
        <a href="https://eecs.engin.umich.edu/"><b>University of Michigan</b></a>&nbsp;&nbsp;&nbsp;
        <a href="https://www.csail.mit.edu/"><b>MIT CSAIL</b></a><br>
    </div>
</div>
<br>
<br>
<br>

<div class="container">
    <h3 id="home" style="padding-top: 80px; margin-top: -80px;"></h3>
    <div class="row align-items-center">
        <div class="col justify-content-center text-center">
            <video width="85%" playsinline="" autoplay="" loop="" preload="" muted="">
                <source src="img/clevr_teaser.mp4" type="video/mp4">
            </video>
        </div>
    </div>
    <hr class="my-4">
</div>
<!-- <br> -->

<!-- <h3 id="interactive_demo" style="padding-top: 80px; margin-top: -80px; text-align: center;">Interactive Demo</h3> -->
<div class="container">
    <h3 id="interactive_demo" style="padding-top: 80px; margin-top: -80px;">Interactive Demo</h3>
    <br>
    <div class="row">
        <div class="col">
            <div class="section">
                <div class="section" style="text-align: center">
                    <span><strong>Text Prompt: </strong></span><br>
                    <span>A small gray rubber cube</span>
                    <label for="clevr_rel">
                        <select id='clevr_rel' class="dropselect" style="text-align: center" name="clevr_generation_1" onchange="setImageClevr(this);">
                            <option value="img/clevr_generation_1_relation/a small gray rubber cube to the left of a small purple metal cube.png">to the left of</option>
                            <option value="img/clevr_generation_1_relation/a small gray rubber cube to the right of a small purple metal cube.png" selected="">to the right of</option>
                            <option value="img/clevr_generation_1_relation/a small gray rubber cube above a small purple metal cube.png">above</option>
                            <option value="img/clevr_generation_1_relation/a small gray rubber cube below a small purple metal cube.png">below</option>
                            <option value="img/clevr_generation_1_relation/a small gray rubber cube in front of a small purple metal cube.png">in front of</option>
                            <option value="img/clevr_generation_1_relation/a small gray rubber cube behind a small purple metal cube.png">behind</option>
                        </select>
                    </label>
                    <span>a small purple metal cube</span>
                </div>
                <div class="row align-items-center">
                    <div class="col justify-content-center text-center">
                        <img src="img/clevr_generation_1_relation/a small gray rubber cube to the right of a small purple metal cube.png"
                             class="img-fluid" alt="" style="width:100%; height:100%" name="image-swap-1">
                    </div>
                </div>
            </div>
        </div>
        <div class="col">
            <div class="section">
                <div class="section" style="text-align: center">
                    <span><strong>Text Prompt: </strong></span><br>
                    <span>A maple wood cabinet</span>
                    <label for="igibson_rel">
                        <select id='igibson_rel' class="dropselect" style="text-align: center" name="igibson_generation_1" onchange="setImageiGibson(this);">
                            <option value="img/igibson_generation_1_relation/cabinet left couch.png">to the left of</option>
                            <option value="img/igibson_generation_1_relation/cabinet right couch.png" selected="">to the right of</option>
                            <option value="img/igibson_generation_1_relation/cabinet front couch.png">in front of</option>
                            <option value="img/igibson_generation_1_relation/cabinet behind couch.png">behind</option>
                        </select>
                    </label>
                    <span>a blue fabric couch</span>
                </div>
                 <div class="row align-items-center">
                    <div class="col justify-content-center text-center">
                        <img src="img/igibson_generation_1_relation/cabinet right couch.png"
                             class="img-fluid" alt="" style="width:100%; height:100%" name="image-swap-2">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Abstract -->
<div class="container">
    <hr class="my-4">
    <h3 id="Abstract" style="padding-top: 80px; margin-top: -80px;">Abstract</h3>
    The visual world around us can be described as a structured set of objects and their associated relations.
    An image of a room may be conjured given only the description of the underlying objects and their associated relations.
    While there has been significant work on designing deep neural networks which may compose individual objects together,
    less work has been done on composing the individual relations between objects.
    A principal difficulty is that while the placement of objects is mutually independent,
    their relations are entangled and dependent on each other.
    To circumvent this issue, existing works primarily compose relations by utilizing a holistic encoder, in the form of text or graphs.
    In this work, we instead propose to represent each relation as an unnormalized density (an energy-based model),
    enabling us to compose separate relations in a factorized manner.
    We show that such a factorized decomposition allows the model to both generate and edit scenes that have multiple sets of relations more faithfully.
    We further show that decomposition enables our model to effectively understand the underlying relational scene structure.
</div>
<br><br>


<!-- Paper -->
<div class="container">
    <h3 id="Paper" style="padding-top: 80px; margin-top: -80px;">Paper</h3>

    <div class="row">
        <div class="col-md-12">
            <b>Learning to Compose Visual Relations</b><br>
            <a href="https://nanliu.io/">Nan Liu</a><sup>1*</sup> &nbsp;
            <a href="https://shuangli59.github.io/">Shuang Li</a><sup>2*</sup> &nbsp;
            <a href="https://yilundu.github.io">Yilun Du</a><sup>2*</sup> &nbsp;
            <a href="https://mitibmwatsonailab.mit.edu/people/joshua-tenenbaum/">Joshua B. Tenenbaum</a><sup>2</sup>
            &nbsp;
            <a href="https://groups.csail.mit.edu/vision/torralbalab/">Antonio Torralba</a><sup>2</sup><br>
            (* indicate equal contribution) <br>
            <b>NeurIPS 2021 (Spotlight)</b>
            <a href="https://github.com/nanlliu/compose-visual-relations" target="_blank">[Code]</a>
            <a href="https://arxiv.org/abs/2111.09297">[Paper]</a>
<!--             <a href="#bibtex">[BibTex]</a><br> -->
            <!--            Abridged in <b>NeurIPS 2021</b> workshop on Visual Learning and Reasoning for Robotics <a href="https://rssvlrr.github.io/">[Link]</a><br>-->
        </div>
    </div>
</div>
<br>
<!-- <br> -->

<div class="container">
    <hr class="my-4">
    <h3 id="Model" style="padding-top: 80px; margin-top: -80px;">Model Overview</h3>
    <div class="row align-items-center">
        <div class="col justify-content-center text-center">
            <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                <source src="img/model.mp4" type="video/mp4">
            </video>
        </div>
    </div>
</div>
<br>

<div class="container">
    <hr class="my-4">
     <h3 id="Results" style="padding-top: 80px; margin-top: -80px;">Image Generation Results</h3><br>
    <div class="section">
        <!-- <h4 class="text-center">Image Generation Results</h4> -->
        <!-- <hr class="my-4"> -->
        <p>
            Image generation results on the <b>CLEVR</b> dataset.
            Image are generated based on <b>1 - 4</b> relational descriptions.
            Note that the models are trained on a single relational description and <b>the composed scene relations (2, 3, and 4 relational descriptions) are outside the training distribution</b>.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/generation_clevr.png" class="img-fluid" alt="" style="width:100%; height:100%">
            </div>
        </div>
        <hr class="my-4">
        <p>
            Image generation results on the <b>iGibson</b> dataset. Below are generated iGibson images.
            Note that the models are trained on a single relational description and <b>the composed scene relations (2 relational descriptions) are outside the training distribution</b>.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/generation_igibson.png" class="img-fluid" alt="" style="width:100%; height:100%">
            </div>
        </div>
        <hr class="my-4">
        <p>
            Image generation results on the <a href="https://arxiv.org/pdf/1603.01312.pdf"><b>real world Blocks dataset</b></a>. 
            Note that the models are trained on a single relational description and <b>the composed scene relations (2 and 3 relational descriptions) are outside the training distribution</b>.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/generation_block.png" class="img-fluid" alt="" style="width:100%; height:100%">
            </div>
        </div>
    </div>
    <br>
    <br>

    <div class="section">
        <hr class="my-4">
        <h3 style="padding-top: 80px; margin-top: -80px;">Image Editing Results</h3><br>
        <!-- <h4 class="text-center">Image Editing Results</h4> -->
        <p> Image editing results on the CLEVR dataset. <b>Left</b>: image editing results based on a single relational scene description.
            <b>Right</b>: image editing results based on two composed relational scene descriptions.
            Note that the composed scene relations in the right part are outside the training distribution and our approach can still edit the images accurately.
        </p>
         <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/editing_clevr.png" class="img-fluid" alt="" style="width:100%; height:100%">
            </div>
        </div>
    </div>
    <br>
    <br>

    <div class="section">
        <hr class="my-4">
        <h3 style="padding-top: 80px; margin-top: -80px;">Image-text Retrieval Results</h3><br>
        <!-- <h4 class="text-center">Image-text Retrieval Results</h4> -->
        <p> We evaluate whether our proposed model can understand different relational scene descriptions by image-to-text retrieval.
            We compare the proposed approach with the pretrained CLIP and fine-tuned CLIP and show their top-1 retrieved relation description based on the given image query.
        </p>
         <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/retrieval.png" class="img-fluid" alt="" style="width:100%; height:100%">
            </div>
        </div>
    </div>
</div>
<br>

<div class="container" id="Related">
    <hr class="my-4">
    <h3>Related Projects</h3>
    <p>
        Check out our related projects on compositional energy functions! <br>
    </p>

    <div class="row vspace-top">
        <div class="col-sm-3">
            <img src="img/posited_factors_global.png" class="img-fluid">
        </div>

        <div class="col">
            <div class="paper-title">
                <a href="https://energy-based-model.github.io/comet/">Unsupervised Learning of Compositional Energy Concepts</a>
            </div>
            <div>
               We show COMET provides a unified framework enabling us to decompose images into both global factors
                of variation as well as local factors of variation. Second, we show that COMET enables us to
                scale to more realistic datasets than previous work. Finally, we show that components obtained by
                COMET generalize well, and are amenable to compositions across different modes of data, and with
                components discovered by other instances of COMET.
            </div>
        </div>
    </div>

    <div class="row vspace-top">
        <div class="col-sm-3">
            <img src="img/comp_cartoon.png" class="img-fluid">
        </div>

        <div class="col">
            <div class="paper-title">
                <a href="https://energy-based-model.github.io/compositional-generation-inference/">Compositional Visual Generation with Energy Based Models</a>
            </div>
            <div>
                We show how EBMs enable <b>zero-shot compositional</b> visual generation, enabling us to compose visual concepts
                (through operators of conjunction, disjunction, or negation) together in a zero-shot manner.
                Our approach enables us to generate faces given a  description
                ((Smiling AND Female) OR (NOT Smiling AND Male)) or to combine several different objects together.
            </div>
        </div>
    </div>

    <div class="row vspace-top">
        <div class="col-sm-3">
            <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                <source src="img/uncond_gen_half.mp4" type="video/mp4">
            </video>
        </div>

        <div class="col">
            <div class="paper-title">
                <a href="https://arxiv.org/abs/2012.01316">Improved Contrastive Divergence Training of Energy Based Models</a>
            </div>
            <div>
                We show that the traditional contrastive divergence training objective used to train EBMs
                is omits a important gradient term. We propose a loss to represent this missing gradient
                and propose additional tricks to improve EBM training. We show that our resultant models
                are able to generate high resolutions images and are further able to compose with each
                other.
            </div>
        </div>
    </div>

    <div class="row vspace-top">
        <div class="col-sm-3">
            <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                <source src="img/half.mp4" type="video/mp4">
            </video>
        </div>

        <div class="col">
            <div class="paper-title">
                <a href="https://openai.com/blog/energy-based-models/">Implicit Generation and Generalization with Energy Based Models</a>

            </div>
            <div>
                We introduce a method to scale EBM training to modern neural network architectures.
                We show that such trained EBMs have a set of unique properties, enabling model robustness,
                image and trajectory modeling, continual learning and compositional visual generation.
            </div>
        </div>
    </div>
</div>
<br>

<!--            <div class="section">-->
<!--                <h2>Paper</h2>-->
<!--                <hr>-->
<!--                <div>-->
<!--                    <div class="list-group">-->
<!--                        <a href="" class="list-group-item">-->
<!--                            <img src="img/paper_thumbnail.png" style="width:100%; margin-right:-20px; margin-top:-10px;">-->
<!--                        </a>-->
<!--                    </div>-->
<!--                </div>-->
<!--            </div>-->

<!-- <div class="container" id="bibtex">
    <hr>
    <h3>Bibtex</h3>
    <div class="bibtexsection">
        @inproceedings{liu2021learning,
          title={Learning to Compose Visual Relations},
          author={Liu, Nan and Li, Shuang and Du, Yilun and Tenenbaum, Joshua B and Torralba, Antonio},
          booktitle={Thirty-Fifth Conference on Neural Information Processing Systems},
          year={2021}
        }
    </div>
</div> -->

<div class="container" id="Contact">
    <hr class="my-4">
    <footer>
        <p>Send feedback and questions to any of
            <a href="https://nanliu.io">Nan Liu</a>,
            <a href="https://people.csail.mit.edu/lishuang/">Shuang Li</a>, and
            <a href="https://yilundu.github.io/">Yilun Du</a>.
        </p>
    </footer>
</div>

<!-- Bootstrap core JavaScript -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
        integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js"
        integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4"
        crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js"
        integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1"
        crossorigin="anonymous"></script>
</body>

</html>
